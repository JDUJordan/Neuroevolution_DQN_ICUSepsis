{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State dict keys: odict_keys(['network.0.weight', 'network.0.bias', 'network.2.weight', 'network.2.bias', 'network.4.weight', 'network.4.bias'])\n",
      "Successfully loaded weights!\n",
      "\n",
      "Model Architecture:\n",
      "QNetwork(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=716, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=25, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordan Lankford\\AppData\\Local\\Temp\\ipykernel_10316\\2027990685.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Add the root directory to Python path\n",
    "root_dir = \"C:\\\\Users\\\\Jordan Lankford\\\\Documents\\\\GitHub\\\\FineTune-DQN\"\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "\n",
    "# Now imports should work\n",
    "from src.utils.utils import set_seeds\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from src.utils.utils import set_seeds\n",
    "from torchsummary import summary\n",
    "\n",
    "def encode_state(obs, n_states):\n",
    "    obs = torch.Tensor(obs)\n",
    "    return nn.functional.one_hot(obs.long(), n_states).float()\n",
    "\n",
    "def get_mask(info, n_actions=25):\n",
    "    allowed_actions = info['admissible_actions']\n",
    "    mask = np.zeros(n_actions)\n",
    "    mask[allowed_actions] = 1\n",
    "    return torch.Tensor(mask).unsqueeze(0)\n",
    "\n",
    "# Modified QNetwork to match the deep DQN structure\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.n_states = env.observation_space.n\n",
    "        self.n_actions = env.action_space.n\n",
    "        \n",
    "        # Match the architecture of the deep DQN\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(self.n_states, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, self.n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, action_masks=None):\n",
    "        q_values = self.network(x)\n",
    "        if action_masks is not None:\n",
    "            q_values = q_values - ((1 - action_masks) * 1e10)\n",
    "        return q_values\n",
    "\n",
    "# Create environment and network\n",
    "env = gym.make('Sepsis/ICU-Sepsis-v2')\n",
    "q_network = QNetwork(env)\n",
    "\n",
    "# Load the trained deep DQN weights\n",
    "model_path = r\"C:\\Users\\Jordan Lankford\\Documents\\GitHub\\FineTune-DQN\\models\\dqn\\dqn_final_seed_0.pt\"\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# Print the keys in the state dict to verify structure\n",
    "print(\"State dict keys:\", state_dict.keys())\n",
    "\n",
    "# Load the weights\n",
    "try:\n",
    "    q_network.load_state_dict(state_dict)\n",
    "    print(\"Successfully loaded weights!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading weights: {e}\")\n",
    "    # Try loading with strict=False if there are issues\n",
    "    q_network.load_state_dict(state_dict, strict=False)\n",
    "    print(\"Loaded weights with strict=False\")\n",
    "\n",
    "# Print model structure\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(q_network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([128, 716]), torch.Size([128]), torch.Size([128, 128]), torch.Size([128]), torch.Size([25, 128]), torch.Size([25])]\n"
     ]
    }
   ],
   "source": [
    "weight_shapes = []\n",
    "for param in q_network.parameters():\n",
    "    weight_shapes.append(param.shape)\n",
    "print(weight_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(91648), np.int64(128), np.int64(16384), np.int64(128), np.int64(3200), np.int64(25)]\n"
     ]
    }
   ],
   "source": [
    "values_in_dimension=[]\n",
    "for shape in weight_shapes:\n",
    "    values_in_dimension.append(np.prod(shape))\n",
    "print(values_in_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [param.detach().numpy() for param in q_network.parameters()]  # Get all model weights as numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from torchsummary import summary\n",
    "\n",
    "# Assuming QNetwork and set_seeds are defined earlier in the code\n",
    "# Assuming the reshape function is defined as needed\n",
    "\n",
    "\n",
    "def f(fly, flies_history, model=q_network,env=env):\n",
    "    # Clone the model (you don't really need to clone in PyTorch, just create a new instance)\n",
    "    cloned_model = q_network\n",
    "    \n",
    "    # Reshape fly's weights to match the model's weight shape\n",
    "    reshaped_fly = reshape_to_model_weights(fly, model)\n",
    "    \n",
    "    # Load the reshaped weights into the cloned model\n",
    "    cloned_model.load_state_dict(dict(zip([name for name, _ in cloned_model.named_parameters()], reshaped_fly)))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    cloned_model.eval()\n",
    "\n",
    "    # Run the evaluation (similar to what is done in evaluate_network)\n",
    "    episode_rewards = []\n",
    "    episode_lengths = []\n",
    "    \n",
    "    num_episodes = 10000  # or any other number you'd like to test  USE 100000 FOR STABAL ISH\n",
    "    for episode in range(num_episodes):\n",
    "        state, info = env.reset()\n",
    "        episode_reward = 0\n",
    "        steps = 0\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            state_encoded = encode_state(np.array([state]), env.observation_space.n)\n",
    "            action_mask = get_mask(info, n_actions=env.action_space.n)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                q_values = cloned_model(state_encoded, action_mask)\n",
    "                action = torch.argmax(q_values).item()\n",
    "            \n",
    "            next_state, reward, terminated, truncated, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "            steps += 1\n",
    "            state = next_state\n",
    "            done = terminated or truncated\n",
    "\n",
    "        episode_rewards.append(episode_reward)\n",
    "        episode_lengths.append(steps)\n",
    "    \n",
    "\n",
    "    fitness = np.mean(episode_rewards)\n",
    "    # Return the average reward (or any other metric you want)\n",
    "    return -f_avrg(fitness, flies_history)\n",
    "    #return -fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_model_weights(flattened_fly, model=q_network):\n",
    "    # List to store reshaped weights\n",
    "    reshaped_weights = []\n",
    "    counter = 0  # Counter for elements in fly\n",
    "    \n",
    "    # Get the shapes of the model's parameters\n",
    "    values_in_dimension = [param.numel() for param in model.parameters()]\n",
    "    weight_shapes = [param.shape for param in model.parameters()]\n",
    "    \n",
    "    for i in range(len(values_in_dimension)):\n",
    "        # Get the flattened weights for this layer\n",
    "        weight_flat = flattened_fly[counter: counter + values_in_dimension[i]]\n",
    "        \n",
    "        # Reshape and convert to torch.Tensor\n",
    "        reshaped_layer_weights = torch.tensor(weight_flat, dtype=torch.float32).reshape(weight_shapes[i])\n",
    "        \n",
    "        # Append the reshaped weight to the list\n",
    "        reshaped_weights.append(reshaped_layer_weights)\n",
    "        \n",
    "        # Move the counter to the next parameter block\n",
    "        counter += values_in_dimension[i]\n",
    "    \n",
    "    return reshaped_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_flies_from_model(number_of_flies, weights, model, inclusive):\n",
    "    population = []\n",
    "\n",
    "    if inclusive == False:\n",
    "        for i in range(number_of_flies):\n",
    "            fly = []  # This will hold the flattened weights for a single fly\n",
    "            \n",
    "            for param in model.parameters():  # Iterate through model parameters (weights and biases)\n",
    "                # Generate random weights with the same shape as the model's weight matrix\n",
    "                scalers = np.random.uniform(0.9, 1.1, size=param.shape)\n",
    "                print(param.shape)  # Print the shape to see what the weights look like\n",
    "                scaledweights = param.detach().numpy() * scalers  # Multiply the weight values by the scalers\n",
    "                \n",
    "                # Flatten the random weights and add them to the fly\n",
    "                flattened_weights = scaledweights.flatten()\n",
    "                fly.append(flattened_weights)\n",
    "            \n",
    "            # After flattening each layer's weights, flatten the entire fly and add to population\n",
    "            population.append(np.concatenate(fly))  # Concatenate the list of flattened weight arrays\n",
    "            \n",
    "    if inclusive == True:\n",
    "        for i in range(number_of_flies):\n",
    "            fly = []  # This will hold the flattened weights for a single fly\n",
    "            \n",
    "            for param in model.parameters():  # Iterate through model parameters (weights and biases)\n",
    "                if i == 0:\n",
    "                    flattened_weights = param.detach().numpy().flatten()  # Get the flattened weights for the first fly\n",
    "                    fly.append(flattened_weights)\n",
    "                else:\n",
    "                    scalers = np.random.uniform(0.9, 1.1, size=param.shape)\n",
    "                    print(param.shape)  # Print the shape to see what the weights look like\n",
    "                    scaledweights = param.detach().numpy() * scalers  # Multiply the weight values by the scalers\n",
    "                    \n",
    "                    # Flatten the random weights and add them to the fly\n",
    "                    flattened_weights = scaledweights.flatten()\n",
    "                    fly.append(flattened_weights)\n",
    "                \n",
    "            # After flattening each layer's weights, flatten the entire fly and add to population\n",
    "            population.append(np.concatenate(fly))  # Concatenate the list of flattened weight arrays\n",
    "        \n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_flies = 1\n",
    "\n",
    "flies = initialize_flies_from_model(num_of_flies,weights,q_network,True)\n",
    "\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "max_history = 5\n",
    "flies_history = [deque(maxlen=max_history) for _ in range(num_of_flies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([], maxlen=5)\n"
     ]
    }
   ],
   "source": [
    "print(flies_history[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_avrg(fitness, flies_history):\n",
    "\n",
    "    flies_history.append(fitness)\n",
    "\n",
    "    print(flies_history)\n",
    "\n",
    "    return sum(flies_history) / len(flies_history) # mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([np.float64(0.8113)], maxlen=5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-0.8113)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(flies[0],flies_history[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111513"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(flies)\t\t\t# POPULATION SIZE\n",
    "D = len(flies[0])\t\t\t\t\t# DIMENSIONALITY \n",
    "delta = 0.005\t\t\t# DISTURBANCE THRESHOLD \n",
    "maxIterations = 1\t# ITERATIONS ALLOWED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFO(start_flies):\n",
    "    \"\"\"\n",
    "    Vectorized DFO implementation for DQN weight optimization\n",
    "    \"\"\"\n",
    "    #N = len(start_flies)          # Population size\n",
    "    #D = len(start_flies[0])       # Dimensionality of weights\n",
    "    #delta = 0.005                 # Disturbance threshold\n",
    "    #maxIterations = 1000          # Max iterations allowed\n",
    "\n",
    "    # Initialize population matrix\n",
    "    X = np.array(start_flies)     # Shape: (N, D)\n",
    "    fitness = np.zeros(N)         # Array to store fitness values\n",
    "    flies_history = [deque(maxlen=5) for _ in range(N)]  # History for each fly\n",
    "\n",
    "    # Initial evaluation of all flies\n",
    "    for i in range(N):\n",
    "        fitness[i] = f(X[i], flies_history[i])\n",
    "    \n",
    "    # Find initial best fly\n",
    "    s = np.argmin(fitness)\n",
    "    \n",
    "    # Main DFO loop\n",
    "    for itr in range(maxIterations):\n",
    "        if itr % 1 == 0:\n",
    "            print(f\"Iteration: {itr}, Best fly index: {s}, Fitness value: {fitness[s]:.3f}, delta: {delta}\")\n",
    "\n",
    "        # Update each fly except the best one\n",
    "        for i in range(N):\n",
    "            if i == s:\n",
    "                continue  # Skip best fly (elitist strategy)\n",
    "\n",
    "            # Find best neighbor\n",
    "            left = (i-1) % N\n",
    "            right = (i+1) % N\n",
    "            bNeighbour = right if fitness[right] < fitness[left] else left\n",
    "\n",
    "            # Generate random numbers for vectorized operations\n",
    "            U = np.random.uniform(0, 1, D)\n",
    "            R = np.random.uniform(0, 1, D)\n",
    "\n",
    "            # Vectorized position update\n",
    "            X[i] = np.where(R < delta,\n",
    "                           np.random.normal(loc=X[bNeighbour], scale=delta),\n",
    "                           X[bNeighbour] + U * (X[s] - X[bNeighbour]))      #if r<delta do random else do the other selfless update\n",
    "\n",
    "            # Evaluate new position\n",
    "            fitness[i] = f(X[i], flies_history[i])\n",
    "\n",
    "        # Update best fly\n",
    "        new_s = np.argmin(fitness)\n",
    "        s = new_s\n",
    "\n",
    "    return X[s]  # Return best solution found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([np.float64(0.8119)], maxlen=5)\n",
      "Iteration: 0, Best fly index: 0, Fitness value: -0.812, delta: 0.005\n"
     ]
    }
   ],
   "source": [
    "newweihgts = DFO(flies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('realbest_fly_weights.npy', newweihgts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
