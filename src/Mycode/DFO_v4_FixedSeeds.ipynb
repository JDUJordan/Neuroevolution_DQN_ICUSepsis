{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State dict keys: odict_keys(['network.0.weight', 'network.0.bias', 'network.2.weight', 'network.2.bias', 'network.4.weight', 'network.4.bias'])\n",
      "Successfully loaded weights!\n",
      "\n",
      "Model Architecture:\n",
      "QNetwork(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=716, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=25, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordan Lankford\\AppData\\Local\\Temp\\ipykernel_8356\\2027990685.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Add the root directory to Python path\n",
    "root_dir = \"C:\\\\Users\\\\Jordan Lankford\\\\Documents\\\\GitHub\\\\FineTune-DQN\"\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "\n",
    "# Now imports should work\n",
    "from src.utils.utils import set_seeds\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from src.utils.utils import set_seeds\n",
    "from torchsummary import summary\n",
    "\n",
    "def encode_state(obs, n_states):\n",
    "    obs = torch.Tensor(obs)\n",
    "    return nn.functional.one_hot(obs.long(), n_states).float()\n",
    "\n",
    "def get_mask(info, n_actions=25):\n",
    "    allowed_actions = info['admissible_actions']\n",
    "    mask = np.zeros(n_actions)\n",
    "    mask[allowed_actions] = 1\n",
    "    return torch.Tensor(mask).unsqueeze(0)\n",
    "\n",
    "# Modified QNetwork to match the deep DQN structure\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.n_states = env.observation_space.n\n",
    "        self.n_actions = env.action_space.n\n",
    "        \n",
    "        # Match the architecture of the deep DQN\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(self.n_states, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, self.n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, action_masks=None):\n",
    "        q_values = self.network(x)\n",
    "        if action_masks is not None:\n",
    "            q_values = q_values - ((1 - action_masks) * 1e10)\n",
    "        return q_values\n",
    "\n",
    "# Create environment and network\n",
    "env = gym.make('Sepsis/ICU-Sepsis-v2')\n",
    "q_network = QNetwork(env)\n",
    "\n",
    "# Load the trained deep DQN weights\n",
    "model_path = r\"C:\\Users\\Jordan Lankford\\Documents\\GitHub\\FineTune-DQN\\models\\dqn\\dqn_final_seed_0.pt\"\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# Print the keys in the state dict to verify structure\n",
    "print(\"State dict keys:\", state_dict.keys())\n",
    "\n",
    "# Load the weights\n",
    "try:\n",
    "    q_network.load_state_dict(state_dict)\n",
    "    print(\"Successfully loaded weights!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading weights: {e}\")\n",
    "    # Try loading with strict=False if there are issues\n",
    "    q_network.load_state_dict(state_dict, strict=False)\n",
    "    print(\"Loaded weights with strict=False\")\n",
    "\n",
    "# Print model structure\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(q_network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([128, 716]), torch.Size([128]), torch.Size([128, 128]), torch.Size([128]), torch.Size([25, 128]), torch.Size([25])]\n"
     ]
    }
   ],
   "source": [
    "weight_shapes = []\n",
    "for param in q_network.parameters():\n",
    "    weight_shapes.append(param.shape)\n",
    "print(weight_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(91648), np.int64(128), np.int64(16384), np.int64(128), np.int64(3200), np.int64(25)]\n"
     ]
    }
   ],
   "source": [
    "values_in_dimension=[]\n",
    "for shape in weight_shapes:\n",
    "    values_in_dimension.append(np.prod(shape))\n",
    "print(values_in_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [param.detach().numpy() for param in q_network.parameters()]  # Get all model weights as numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(fly, flies_history=None, model=q_network, env=env, eval_seeds=[0, 1, 2, 3, 4]):\n",
    "    \"\"\"Use fixed seeds for more consistent evaluation while maintaining some variety\"\"\"\n",
    "    cloned_model = q_network\n",
    "    reshaped_fly = reshape_to_model_weights(fly, model)\n",
    "    cloned_model.load_state_dict(dict(zip([name for name, _ in cloned_model.named_parameters()], reshaped_fly)))\n",
    "    cloned_model.eval()\n",
    "\n",
    "    episode_rewards = []\n",
    "    episodes_per_seed = 4000  # 20000 total episodes divided among 5 seeds\n",
    "    \n",
    "    for seed in eval_seeds:\n",
    "        env.reset(seed=seed)  # Set environment seed\n",
    "        \n",
    "        for episode in range(episodes_per_seed):\n",
    "            state, info = env.reset()\n",
    "            episode_reward = 0\n",
    "            done = False\n",
    "            \n",
    "            while not done:\n",
    "                state_encoded = encode_state(np.array([state]), env.observation_space.n)\n",
    "                action_mask = get_mask(info, n_actions=env.action_space.n)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    q_values = cloned_model(state_encoded, action_mask)\n",
    "                    action = torch.argmax(q_values).item()\n",
    "                \n",
    "                next_state, reward, terminated, truncated, info = env.step(action)\n",
    "                episode_reward += reward\n",
    "                state = next_state\n",
    "                done = terminated or truncated\n",
    "\n",
    "            episode_rewards.append(episode_reward)\n",
    "\n",
    "    fitness = np.mean(episode_rewards)\n",
    "    return -fitness\n",
    "    #return -f_avrg(fitness, flies_history) if flies_history is not None else -fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m fitness_values \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     fitness_values\u001b[38;5;241m.\u001b[39mappend(f(\u001b[43mflies\u001b[49m[\u001b[38;5;241m0\u001b[39m], flies_history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, model\u001b[38;5;241m=\u001b[39mq_network,env\u001b[38;5;241m=\u001b[39menv))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(fitness_values)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#range of fitness values\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'flies' is not defined"
     ]
    }
   ],
   "source": [
    "#run fly through the fitness function 20 times, calculate the range in fitness values\n",
    "\n",
    "#f(fly, flies_history = None, model=q_network,env=env)\n",
    "fitness_values = []\n",
    "for i in range(10):\n",
    "    fitness_values.append(f(flies[0], flies_history = None, model=q_network,env=env))\n",
    "\n",
    "print(fitness_values)\n",
    "#range of fitness values\n",
    "range_fitness = max(fitness_values) - min(fitness_values)\n",
    "print(range_fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard deviation of fitness values\n",
    "std_fitness = np.std(fitness_values)\n",
    "print(std_fitness)\n",
    "#mean of fitness values\n",
    "mean_fitness = np.mean(fitness_values)\n",
    "print(mean_fitness)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    #take the firtst ith number of flies and caluculate mean fitness\n",
    "    mean_fitness = np.mean(fitness_values[:i])\n",
    "    print(\"mean when using\", i ,\"flies:\", mean_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_model_weights(flattened_fly, model=q_network):\n",
    "    # List to store reshaped weights\n",
    "    reshaped_weights = []\n",
    "    counter = 0  # Counter for elements in fly\n",
    "    \n",
    "    # Get the shapes of the model's parameters\n",
    "    values_in_dimension = [param.numel() for param in model.parameters()]\n",
    "    weight_shapes = [param.shape for param in model.parameters()]\n",
    "    \n",
    "    for i in range(len(values_in_dimension)):\n",
    "        # Get the flattened weights for this layer\n",
    "        weight_flat = flattened_fly[counter: counter + values_in_dimension[i]]\n",
    "        \n",
    "        # Reshape and convert to torch.Tensor\n",
    "        reshaped_layer_weights = torch.tensor(weight_flat, dtype=torch.float32).reshape(weight_shapes[i])\n",
    "        \n",
    "        # Append the reshaped weight to the list\n",
    "        reshaped_weights.append(reshaped_layer_weights)\n",
    "        \n",
    "        # Move the counter to the next parameter block\n",
    "        counter += values_in_dimension[i]\n",
    "    \n",
    "    return reshaped_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_flies_from_model(number_of_flies, weights, model, inclusive):\n",
    "    population = []\n",
    "\n",
    "    if inclusive == False:\n",
    "        for i in range(number_of_flies):\n",
    "            fly = []  # This will hold the flattened weights for a single fly\n",
    "            \n",
    "            for param in model.parameters():  # Iterate through model parameters (weights and biases)\n",
    "                # Generate random weights with the same shape as the model's weight matrix\n",
    "                scalers = np.random.uniform(0.9, 1.1, size=param.shape)\n",
    "                print(param.shape)  # Print the shape to see what the weights look like\n",
    "                scaledweights = param.detach().numpy() * scalers  # Multiply the weight values by the scalers\n",
    "                \n",
    "                # Flatten the random weights and add them to the fly\n",
    "                flattened_weights = scaledweights.flatten()\n",
    "                fly.append(flattened_weights)\n",
    "            \n",
    "            # After flattening each layer's weights, flatten the entire fly and add to population\n",
    "            population.append(np.concatenate(fly))  # Concatenate the list of flattened weight arrays\n",
    "            \n",
    "    if inclusive == True:\n",
    "        for i in range(number_of_flies):\n",
    "            fly = []  # This will hold the flattened weights for a single fly\n",
    "            \n",
    "            for param in model.parameters():  # Iterate through model parameters (weights and biases)\n",
    "                if i == 0:\n",
    "                    flattened_weights = param.detach().numpy().flatten()  # Get the flattened weights for the first fly\n",
    "                    fly.append(flattened_weights)\n",
    "                else:\n",
    "                    scalers = np.random.uniform(0.9, 1.1, size=param.shape)\n",
    "                    print(param.shape)  # Print the shape to see what the weights look like\n",
    "                    scaledweights = param.detach().numpy() * scalers  # Multiply the weight values by the scalers\n",
    "                    \n",
    "                    # Flatten the random weights and add them to the fly\n",
    "                    flattened_weights = scaledweights.flatten()\n",
    "                    fly.append(flattened_weights)\n",
    "                \n",
    "            # After flattening each layer's weights, flatten the entire fly and add to population\n",
    "            population.append(np.concatenate(fly))  # Concatenate the list of flattened weight arrays\n",
    "        \n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n"
     ]
    }
   ],
   "source": [
    "num_of_flies = 10\n",
    "\n",
    "flies = initialize_flies_from_model(num_of_flies,weights,q_network,True)\n",
    "\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "max_history = 5\n",
    "flies_history = [deque(maxlen=max_history) for _ in range(num_of_flies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flies_history[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_avrg(fitness, flies_history):\n",
    "\n",
    "    flies_history.append(fitness)\n",
    "\n",
    "    print(flies_history)\n",
    "\n",
    "    return sum(flies_history) / len(flies_history) # mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(flies[0],flies_history[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(flies)\t\t\t# POPULATION SIZE\n",
    "D = len(flies[0])\t\t\t\t\t# DIMENSIONALITY \n",
    "#delta = 0.005\t\t\t# DISTURBANCE THRESHOLD \n",
    "maxIterations = 200\t# ITERATIONS ALLOWED\n",
    "sd = np.std(flies[0])\t\t# STANDARD DEVIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Population:\n",
      "Min: -4.9936833\n",
      "Max: 4.964795\n",
      "Range: 9.958479\n",
      "Standard Deviation: 0.1878362\n",
      "Median: 0.0\n"
     ]
    }
   ],
   "source": [
    "#print the min and max values and the range of the initial population\n",
    "min_value = np.min(flies[0])\n",
    "max_value = np.max(flies[0])\n",
    "range_value = max_value - min_value\n",
    "print(\"Initial Population:\")\n",
    "print(\"Min:\", min_value)\n",
    "print(\"Max:\", max_value)\n",
    "print(\"Range:\", range_value)\n",
    "sd = np.std(flies[0])\n",
    "print(\"Standard Deviation:\", sd)\n",
    "median = np.median(flies[0])\n",
    "print(\"Median:\", median)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def disturbance_threashold_mechanism(delta, disturbance_counter, patience):\n",
    "    if delta == 1 and disturbance_counter > patience:\n",
    "        return 0, 0 #delta, disturbance_counter\n",
    "    elif delta != 1 and disturbance_counter > patience:\n",
    "        delta = (delta + np.random.uniform(high=0.5)) #add rand number between 0-0.5\n",
    "        if delta > 1:\n",
    "            return 1, 0\n",
    "        else:\n",
    "            return delta, 0\n",
    "    else:\n",
    "        return delta, disturbance_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFO(start_flies):\n",
    "    \"\"\"\n",
    "    DFO with dynamic delta control and detailed fitness reporting\n",
    "    \"\"\"\n",
    "    X = np.array(start_flies)     \n",
    "    fitness = np.zeros(N)         \n",
    "    #flies_history = [deque(maxlen=5) for _ in range(N)]\n",
    "    disturbance_counter = 0\n",
    "    fitness_history = []\n",
    "    delta_history = []\n",
    "    delta = 1\n",
    "    \n",
    "    for i in range(N):\n",
    "        #fitness[i] = f(X[i], flies_history[i])\n",
    "        fitness[i] = f(X[i])\n",
    "\n",
    "\n",
    "    # Find initial best fly\n",
    "    s = np.argmin(fitness)\n",
    "    \n",
    "    # Main DFO loop\n",
    "    for itr in range(maxIterations):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Iteration: {itr}\")\n",
    "        print(f\"Current delta: {delta:.6f}\")\n",
    "        print(f\"disturbance_counter: {disturbance_counter}\")\n",
    "\n",
    "        for i in range(N):\n",
    "            if i == s:\n",
    "                print(f\"Fly {i} (Best fly) fitness = {fitness[i]:.6f}\")\n",
    "                continue\n",
    "\n",
    "            left = (i-1) % N\n",
    "            right = (i+1) % N\n",
    "            bNeighbour = right if fitness[right] < fitness[left] else left\n",
    "\n",
    "            \n",
    "\n",
    "            U = np.random.uniform(0, 1, D)\n",
    "            R = np.random.uniform(0, 1, D)\n",
    "            X[i] = np.where(R < delta,\n",
    "                           np.random.normal(loc=X[bNeighbour], scale=2*sd),\n",
    "                           X[bNeighbour] + U * (X[s] - X[i]))\n",
    "\n",
    "            #new_fitness = f(X[i], flies_history[i])\n",
    "\n",
    "            #print(f\"\\nFly {i} after update:\")\n",
    "            #print(f\"First 5 dimensions: {X[i][:5]}\")\n",
    "            \n",
    "        \n",
    "\n",
    "            \n",
    "            fitness[i] = f(X[i])\n",
    "            \n",
    "            \n",
    "            \n",
    "        new_s = np.argmin(fitness)\n",
    "        \n",
    "        if new_s <= s:\n",
    "            disturbance_counter += 1\n",
    "            delta, disturbance_counter = disturbance_threashold_mechanism(delta, disturbance_counter, patience=10)\n",
    "        s = new_s\n",
    "            \n",
    "\n",
    "        fitness_history.append(fitness[s])\n",
    "        delta_history.append(delta)\n",
    "        \n",
    "        print(f\"\\nEnd of iteration summary:\")\n",
    "        print(f\"Best fly: {s} with fitness = {fitness[s]:.6f}\")\n",
    "        print(f\"All flies fitness values:\")\n",
    "        for i in range(N):\n",
    "            print(f\"Fly {i}: {fitness[i]:.6f}\")\n",
    "\n",
    "    return X[s], fitness_history, delta_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_solution, fitness_history, delta_history = DFO(flies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('realbest_fly_weights.npy', best_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "newweihgts = np.load('realbest_fly_weights.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving fine tuned weights\n",
    "\n",
    "cloned_model = q_network\n",
    "    # Reshape fly's weights to match the model's weight shape\n",
    "reshaped_fly = reshape_to_model_weights(newweihgts)\n",
    "    \n",
    "    # Load the reshaped weights into the cloned model\n",
    "cloned_model.load_state_dict(dict(zip([name for name, _ in cloned_model.named_parameters()], reshaped_fly)))\n",
    "\n",
    "\n",
    "# save the model as dfoFineTuned\n",
    "torch.save(cloned_model.state_dict(), '1dfoFineTuned.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fitness_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fitness_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Plot fitness[s]\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mfitness_history\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitness (Best Fly)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitness\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fitness_history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results after all iterations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot fitness[s]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(fitness_history, label=\"Fitness (Best Fly)\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.title(\"Fitness vs Iteration\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot delta\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(delta_history, label=\"Delta\", color='orange')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Delta\")\n",
    "plt.title(\"Delta vs Iteration\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
