{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State dict keys: odict_keys(['network.0.weight', 'network.0.bias', 'network.2.weight', 'network.2.bias', 'network.4.weight', 'network.4.bias'])\n",
      "Successfully loaded weights!\n",
      "\n",
      "Model Architecture:\n",
      "QNetwork(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=716, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=25, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordan Lankford\\AppData\\Local\\Temp\\ipykernel_18660\\2027990685.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Add the root directory to Python path\n",
    "root_dir = \"C:\\\\Users\\\\Jordan Lankford\\\\Documents\\\\GitHub\\\\FineTune-DQN\"\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "\n",
    "# Now imports should work\n",
    "from src.utils.utils import set_seeds\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from src.utils.utils import set_seeds\n",
    "from torchsummary import summary\n",
    "\n",
    "def encode_state(obs, n_states):\n",
    "    obs = torch.Tensor(obs)\n",
    "    return nn.functional.one_hot(obs.long(), n_states).float()\n",
    "\n",
    "def get_mask(info, n_actions=25):\n",
    "    allowed_actions = info['admissible_actions']\n",
    "    mask = np.zeros(n_actions)\n",
    "    mask[allowed_actions] = 1\n",
    "    return torch.Tensor(mask).unsqueeze(0)\n",
    "\n",
    "# Modified QNetwork to match the deep DQN structure\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.n_states = env.observation_space.n\n",
    "        self.n_actions = env.action_space.n\n",
    "        \n",
    "        # Match the architecture of the deep DQN\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(self.n_states, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, self.n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, action_masks=None):\n",
    "        q_values = self.network(x)\n",
    "        if action_masks is not None:\n",
    "            q_values = q_values - ((1 - action_masks) * 1e10)\n",
    "        return q_values\n",
    "\n",
    "# Create environment and network\n",
    "env = gym.make('Sepsis/ICU-Sepsis-v2')\n",
    "q_network = QNetwork(env)\n",
    "\n",
    "# Load the trained deep DQN weights\n",
    "model_path = r\"C:\\Users\\Jordan Lankford\\Documents\\GitHub\\FineTune-DQN\\models\\dqn\\dqn_final_seed_0.pt\"\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# Print the keys in the state dict to verify structure\n",
    "print(\"State dict keys:\", state_dict.keys())\n",
    "\n",
    "# Load the weights\n",
    "try:\n",
    "    q_network.load_state_dict(state_dict)\n",
    "    print(\"Successfully loaded weights!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading weights: {e}\")\n",
    "    # Try loading with strict=False if there are issues\n",
    "    q_network.load_state_dict(state_dict, strict=False)\n",
    "    print(\"Loaded weights with strict=False\")\n",
    "\n",
    "# Print model structure\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(q_network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([128, 716]), torch.Size([128]), torch.Size([128, 128]), torch.Size([128]), torch.Size([25, 128]), torch.Size([25])]\n"
     ]
    }
   ],
   "source": [
    "weight_shapes = []\n",
    "for param in q_network.parameters():\n",
    "    weight_shapes.append(param.shape)\n",
    "print(weight_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(91648), np.int64(128), np.int64(16384), np.int64(128), np.int64(3200), np.int64(25)]\n"
     ]
    }
   ],
   "source": [
    "values_in_dimension=[]\n",
    "for shape in weight_shapes:\n",
    "    values_in_dimension.append(np.prod(shape))\n",
    "print(values_in_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [param.detach().numpy() for param in q_network.parameters()]  # Get all model weights as numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "\n",
    "def f(fly, flies_history = None, model=q_network,env=env):\n",
    "    \n",
    "    cloned_model = q_network\n",
    "    \n",
    "    # Reshape fly's weights to match the model's weight shape\n",
    "    reshaped_fly = reshape_to_model_weights(fly, model)\n",
    "    \n",
    "    # Load the reshaped weights into the cloned model\n",
    "    cloned_model.load_state_dict(dict(zip([name for name, _ in cloned_model.named_parameters()], reshaped_fly)))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    cloned_model.eval()\n",
    "\n",
    "    # Run the evaluation (similar to what is done in evaluate_network)\n",
    "    episode_rewards = []\n",
    "    episode_lengths = []\n",
    "    \n",
    "    num_episodes = 20000  # or any other number you'd like to test  USE 10000 FOR STABAL ISH\n",
    "    for episode in range(num_episodes):\n",
    "        state, info = env.reset()\n",
    "        episode_reward = 0\n",
    "        steps = 0\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            state_encoded = encode_state(np.array([state]), env.observation_space.n)\n",
    "            action_mask = get_mask(info, n_actions=env.action_space.n)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                q_values = cloned_model(state_encoded, action_mask)\n",
    "                action = torch.argmax(q_values).item()\n",
    "            \n",
    "            next_state, reward, terminated, truncated, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "            steps += 1\n",
    "            state = next_state\n",
    "            done = terminated or truncated\n",
    "\n",
    "        episode_rewards.append(episode_reward)\n",
    "        episode_lengths.append(steps)\n",
    "    \n",
    "\n",
    "    fitness = np.mean(episode_rewards)\n",
    "    # Return the average reward (or any other metric you want)\n",
    "    return -f_avrg(fitness, flies_history)\n",
    "    #return -fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(-0.8124), np.float64(-0.8074), np.float64(-0.81455), np.float64(-0.80705), np.float64(-0.8125), np.float64(-0.8096), np.float64(-0.80815), np.float64(-0.8064), np.float64(-0.80905), np.float64(-0.8143), np.float64(-0.81195), np.float64(-0.8096), np.float64(-0.80975), np.float64(-0.81325), np.float64(-0.8111), np.float64(-0.80875), np.float64(-0.80945), np.float64(-0.8159), np.float64(-0.8128), np.float64(-0.8118)]\n",
      "0.009499999999999953\n"
     ]
    }
   ],
   "source": [
    "#run fly through the fitness function 20 times, calculate the range in fitness values\n",
    "\n",
    "#f(fly, flies_history = None, model=q_network,env=env)\n",
    "fitness_values = []\n",
    "for i in range(20):\n",
    "    fitness_values.append(f(flies[0], flies_history = None, model=q_network,env=env))\n",
    "\n",
    "print(fitness_values)\n",
    "#range of fitness values\n",
    "range_fitness = max(fitness_values) - min(fitness_values)\n",
    "print(range_fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002600570850794101\n",
      "-0.8107875\n"
     ]
    }
   ],
   "source": [
    "#standard deviation of fitness values\n",
    "std_fitness = np.std(fitness_values)\n",
    "print(std_fitness)\n",
    "#mean of fitness values\n",
    "mean_fitness = np.mean(fitness_values)\n",
    "print(mean_fitness)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean when using 0 flies: nan\n",
      "mean when using 1 flies: -0.8124\n",
      "mean when using 2 flies: -0.8099000000000001\n",
      "mean when using 3 flies: -0.8114500000000001\n",
      "mean when using 4 flies: -0.8103500000000001\n",
      "mean when using 5 flies: -0.8107800000000001\n",
      "mean when using 6 flies: -0.8105833333333333\n",
      "mean when using 7 flies: -0.8102357142857144\n",
      "mean when using 8 flies: -0.80975625\n",
      "mean when using 9 flies: -0.8096777777777777\n",
      "mean when using 10 flies: -0.81014\n",
      "mean when using 11 flies: -0.8103045454545454\n",
      "mean when using 12 flies: -0.8102458333333332\n",
      "mean when using 13 flies: -0.8102076923076922\n",
      "mean when using 14 flies: -0.8104249999999998\n",
      "mean when using 15 flies: -0.8104699999999999\n",
      "mean when using 16 flies: -0.8103625\n",
      "mean when using 17 flies: -0.8103088235294118\n",
      "mean when using 18 flies: -0.8106194444444443\n",
      "mean when using 19 flies: -0.8107342105263157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordan Lankford\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Jordan Lankford\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    #take the firtst ith number of flies and caluculate mean fitness\n",
    "    mean_fitness = np.mean(fitness_values[:i])\n",
    "    print(\"mean when using\", i ,\"flies:\", mean_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sequential evaluation:\n",
      "Sequential result: -0.809\n",
      "Sequential time: 33.63s\n",
      "\n",
      "Testing parallel evaluation:\n",
      "Evaluated 10000 episodes in 50.38 seconds\n",
      "Parallel result: -0.8062\n",
      "Parallel time: 50.39s\n",
      "\n",
      "Speedup: 0.67x\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from parallel_fitness import parallel_fitness, QNetwork\n",
    "import time \n",
    "\n",
    "def f_parallel(fly, model=q_network, num_processes=4):\n",
    "    \"\"\"\n",
    "    Wrapper for parallel fitness evaluation\n",
    "    \"\"\"\n",
    "    reshaped_fly = reshape_to_model_weights(fly, model)\n",
    "    state_dict = dict(zip([name for name, _ in model.named_parameters()], reshaped_fly))\n",
    "    return parallel_fitness(state_dict, num_processes=num_processes)\n",
    "\n",
    "\n",
    "# Compare performance\n",
    "print(\"Testing sequential evaluation:\")\n",
    "start = time.perf_counter()\n",
    "result_seq = f(flies[0])\n",
    "time_seq = time.perf_counter() - start\n",
    "print(f\"Sequential result: {result_seq}\")\n",
    "print(f\"Sequential time: {time_seq:.2f}s\")\n",
    "\n",
    "print(\"\\nTesting parallel evaluation:\")\n",
    "start = time.perf_counter()\n",
    "result_par = f_parallel(flies[0], num_processes=4)\n",
    "time_par = time.perf_counter() - start\n",
    "print(f\"Parallel result: {result_par}\")\n",
    "print(f\"Parallel time: {time_par:.2f}s\")\n",
    "\n",
    "print(f\"\\nSpeedup: {time_seq/time_par:.2f}x\")'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing vectorized evaluation:\n",
      "Evaluated 1068 episodes in 2.43 seconds\n",
      "Vectorized result: -0.0\n",
      "Vectorized time: 3.88s\n",
      "Testing sequential evaluation:\n",
      "Sequential result: -0.8124\n",
      "Sequential time: 37.90s\n",
      "\n",
      "Speedup: 9.77x\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "from vectorized_fitness import vectorized_fitness, QNetwork\n",
    "import time\n",
    "\n",
    "def f_vectorized(fly, model=q_network, num_envs=4):\n",
    "    \"\"\"\n",
    "    Wrapper for vectorized fitness evaluation\n",
    "    \"\"\"\n",
    "    reshaped_fly = reshape_to_model_weights(fly, model)\n",
    "    state_dict = dict(zip([name for name, _ in model.named_parameters()], reshaped_fly))\n",
    "    return vectorized_fitness(state_dict, num_envs=num_envs)\n",
    "\n",
    "# Test code\n",
    "\n",
    "\n",
    "print(\"\\nTesting vectorized evaluation:\")\n",
    "start = time.perf_counter()\n",
    "result_vec = f_vectorized(flies[0], num_envs=4)\n",
    "time_vec = time.perf_counter() - start\n",
    "print(f\"Vectorized result: {result_vec}\")\n",
    "print(f\"Vectorized time: {time_vec:.2f}s\")\n",
    "\n",
    "\n",
    "print(\"Testing sequential evaluation:\")\n",
    "start = time.perf_counter()\n",
    "result_seq = f(flies[0])\n",
    "time_seq = time.perf_counter() - start\n",
    "print(f\"Sequential result: {result_seq}\")\n",
    "print(f\"Sequential time: {time_seq:.2f}s\")\n",
    "\n",
    "print(f\"\\nSpeedup: {time_seq/time_vec:.2f}x\")'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_model_weights(flattened_fly, model=q_network):\n",
    "    # List to store reshaped weights\n",
    "    reshaped_weights = []\n",
    "    counter = 0  # Counter for elements in fly\n",
    "    \n",
    "    # Get the shapes of the model's parameters\n",
    "    values_in_dimension = [param.numel() for param in model.parameters()]\n",
    "    weight_shapes = [param.shape for param in model.parameters()]\n",
    "    \n",
    "    for i in range(len(values_in_dimension)):\n",
    "        # Get the flattened weights for this layer\n",
    "        weight_flat = flattened_fly[counter: counter + values_in_dimension[i]]\n",
    "        \n",
    "        # Reshape and convert to torch.Tensor\n",
    "        reshaped_layer_weights = torch.tensor(weight_flat, dtype=torch.float32).reshape(weight_shapes[i])\n",
    "        \n",
    "        # Append the reshaped weight to the list\n",
    "        reshaped_weights.append(reshaped_layer_weights)\n",
    "        \n",
    "        # Move the counter to the next parameter block\n",
    "        counter += values_in_dimension[i]\n",
    "    \n",
    "    return reshaped_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_flies_from_model(number_of_flies, weights, model, inclusive):\n",
    "    population = []\n",
    "\n",
    "    if inclusive == False:\n",
    "        for i in range(number_of_flies):\n",
    "            fly = []  # This will hold the flattened weights for a single fly\n",
    "            \n",
    "            for param in model.parameters():  # Iterate through model parameters (weights and biases)\n",
    "                # Generate random weights with the same shape as the model's weight matrix\n",
    "                scalers = np.random.uniform(0.9, 1.1, size=param.shape)\n",
    "                print(param.shape)  # Print the shape to see what the weights look like\n",
    "                scaledweights = param.detach().numpy() * scalers  # Multiply the weight values by the scalers\n",
    "                \n",
    "                # Flatten the random weights and add them to the fly\n",
    "                flattened_weights = scaledweights.flatten()\n",
    "                fly.append(flattened_weights)\n",
    "            \n",
    "            # After flattening each layer's weights, flatten the entire fly and add to population\n",
    "            population.append(np.concatenate(fly))  # Concatenate the list of flattened weight arrays\n",
    "            \n",
    "    if inclusive == True:\n",
    "        for i in range(number_of_flies):\n",
    "            fly = []  # This will hold the flattened weights for a single fly\n",
    "            \n",
    "            for param in model.parameters():  # Iterate through model parameters (weights and biases)\n",
    "                if i == 0:\n",
    "                    flattened_weights = param.detach().numpy().flatten()  # Get the flattened weights for the first fly\n",
    "                    fly.append(flattened_weights)\n",
    "                else:\n",
    "                    scalers = np.random.uniform(0.9, 1.1, size=param.shape)\n",
    "                    print(param.shape)  # Print the shape to see what the weights look like\n",
    "                    scaledweights = param.detach().numpy() * scalers  # Multiply the weight values by the scalers\n",
    "                    \n",
    "                    # Flatten the random weights and add them to the fly\n",
    "                    flattened_weights = scaledweights.flatten()\n",
    "                    fly.append(flattened_weights)\n",
    "                \n",
    "            # After flattening each layer's weights, flatten the entire fly and add to population\n",
    "            population.append(np.concatenate(fly))  # Concatenate the list of flattened weight arrays\n",
    "        \n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n"
     ]
    }
   ],
   "source": [
    "num_of_flies = 10\n",
    "\n",
    "flies = initialize_flies_from_model(num_of_flies,weights,q_network,True)\n",
    "\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "max_history = 5\n",
    "flies_history = [deque(maxlen=max_history) for _ in range(num_of_flies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([], maxlen=5)\n"
     ]
    }
   ],
   "source": [
    "print(flies_history[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_avrg(fitness, flies_history):\n",
    "\n",
    "    flies_history.append(fitness)\n",
    "\n",
    "    print(flies_history)\n",
    "\n",
    "    return sum(flies_history) / len(flies_history) # mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(flies[0],flies_history[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(flies)\t\t\t# POPULATION SIZE\n",
    "D = len(flies[0])\t\t\t\t\t# DIMENSIONALITY \n",
    "delta = 0.005\t\t\t# DISTURBANCE THRESHOLD \n",
    "maxIterations = 200\t# ITERATIONS ALLOWED\n",
    "sd = np.std(flies[0])\t\t# STANDARD DEVIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Population:\n",
      "Min: -4.9936833\n",
      "Max: 4.964795\n",
      "Range: 9.958479\n",
      "Standard Deviation: 0.1878362\n",
      "Median: 0.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m median \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmedian(flies[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedian:\u001b[39m\u001b[38;5;124m\"\u001b[39m, median)\n\u001b[1;32m---> 13\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m(flies[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMode:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\__init__.py:428\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mchar\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[1;32m--> 428\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'mode'"
     ]
    }
   ],
   "source": [
    "#print the min and max values and the range of the initial population\n",
    "min_value = np.min(flies[0])\n",
    "max_value = np.max(flies[0])\n",
    "range_value = max_value - min_value\n",
    "print(\"Initial Population:\")\n",
    "print(\"Min:\", min_value)\n",
    "print(\"Max:\", max_value)\n",
    "print(\"Range:\", range_value)\n",
    "sd = np.std(flies[0])\n",
    "print(\"Standard Deviation:\", sd)\n",
    "median = np.median(flies[0])\n",
    "print(\"Median:\", median)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFO(start_flies):\n",
    "    \"\"\"\n",
    "    DFO with initial history population phase\n",
    "    \"\"\"\n",
    "    X = np.array(start_flies)     \n",
    "    fitness = np.zeros(N)         \n",
    "    flies_history = [deque(maxlen=5) for _ in range(N)]\n",
    "\n",
    "    # First phase: Populate histories for all flies\n",
    "    print(\"Populating initial histories...\")\n",
    "    for _ in range(max_history):  # Run evaluations to fill histories\n",
    "        for i in range(N):\n",
    "            fitness[i] = f(X[i], flies_history[i])\n",
    "            print(f\"Fly {i} history: {list(flies_history[i])}\")\n",
    "    \n",
    "    # # Now all flies have full histories, start optimization\n",
    "    s = np.argmin(fitness)\n",
    "    print(f\"\\nStarting optimization with best fly: {s}, fitness: {fitness[s]:.3f}\")\n",
    "    \n",
    "    # Main DFO loop\n",
    "    for itr in range(maxIterations):\n",
    "        # Recalculate best fly's fitness\n",
    "        best_fly_fitness = f(X[s], flies_history[s])\n",
    "        fitness[s] = best_fly_fitness\n",
    "        \n",
    "        print(f\"\\nIteration: {itr}\")\n",
    "        print(f\"Best fly {s} recalculated fitness: {fitness[s]:.3f}\")\n",
    "        print(f\"Best fly history: {list(flies_history[s])}\")\n",
    "\n",
    "        for i in range(N):\n",
    "            if i == s:\n",
    "                continue\n",
    "\n",
    "            left = (i-1) % N\n",
    "            right = (i+1) % N\n",
    "            bNeighbour = right if fitness[right] < fitness[left] else left\n",
    "\n",
    "            old_position = X[i].copy()\n",
    "            old_fitness = fitness[i]\n",
    "\n",
    "            U = np.random.uniform(0, 1, D)\n",
    "            R = np.random.uniform(0, 1, D)\n",
    "            X[i] = np.where(R < delta,\n",
    "                           np.random.normal(loc=X[i], scale=sd), #Change to scale=sd, rather than delta\n",
    "                           X[bNeighbour] + U * (X[s] - X[i])) # MADE BOTH RESSART AND NORMAL USE THE CURRENT FLY RATHER THAN FORCING SELFLESS UPDATE\n",
    "\n",
    "            new_fitness = f(X[i], flies_history[i])\n",
    "            \n",
    "            if new_fitness < old_fitness:\n",
    "                fitness[i] = new_fitness\n",
    "                if new_fitness < fitness[s]:\n",
    "                    s = i\n",
    "                    print(f\"New best found! Fly {i}: {new_fitness:.3f}\")\n",
    "                    print(f\"New best history: {list(flies_history[i])}\")\n",
    "            else:\n",
    "                X[i] = old_position\n",
    "                fitness[i] = old_fitness\n",
    "\n",
    "        # After all flies updated, recheck who is best\n",
    "        s = np.argmin(fitness)\n",
    "        print(f\"End of iteration best fly: {s} with fitness: {fitness[s]:.3f}\")\n",
    "        print(f\"Best fly history: {list(flies_history[s])}\")\n",
    "\n",
    "    return X[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([np.float64(0.81145)], maxlen=5)\n",
      "\n",
      "Iteration: 0\n",
      "Best fly 0 recalculated fitness: -0.811\n",
      "Best fly history: [np.float64(0.81145)]\n",
      "deque([np.float64(0.8033)], maxlen=5)\n",
      "deque([np.float64(0.8029)], maxlen=5)\n",
      "deque([np.float64(0.80995)], maxlen=5)\n",
      "deque([np.float64(0.8073)], maxlen=5)\n",
      "deque([np.float64(0.79635)], maxlen=5)\n",
      "deque([np.float64(0.7914)], maxlen=5)\n",
      "deque([np.float64(0.79)], maxlen=5)\n",
      "deque([np.float64(0.7995)], maxlen=5)\n",
      "deque([np.float64(0.8111)], maxlen=5)\n",
      "End of iteration best fly: 0 with fitness: -0.811\n",
      "Best fly history: [np.float64(0.81145)]\n",
      "deque([np.float64(0.81145), np.float64(0.816)], maxlen=5)\n",
      "\n",
      "Iteration: 1\n",
      "Best fly 0 recalculated fitness: -0.814\n",
      "Best fly history: [np.float64(0.81145), np.float64(0.816)]\n",
      "deque([np.float64(0.8033), np.float64(0.8129)], maxlen=5)\n",
      "deque([np.float64(0.8029), np.float64(0.81395)], maxlen=5)\n",
      "deque([np.float64(0.80995), np.float64(0.81615)], maxlen=5)\n",
      "deque([np.float64(0.8073), np.float64(0.8094)], maxlen=5)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m newweihgts \u001b[38;5;241m=\u001b[39m \u001b[43mDFO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflies\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 47\u001b[0m, in \u001b[0;36mDFO\u001b[1;34m(start_flies)\u001b[0m\n\u001b[0;32m     42\u001b[0m R \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, D)\n\u001b[0;32m     43\u001b[0m X[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(R \u001b[38;5;241m<\u001b[39m delta,\n\u001b[0;32m     44\u001b[0m                np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(loc\u001b[38;5;241m=\u001b[39mX[i], scale\u001b[38;5;241m=\u001b[39msd), \u001b[38;5;66;03m#Change to scale=sd, rather than delta\u001b[39;00m\n\u001b[0;32m     45\u001b[0m                X[bNeighbour] \u001b[38;5;241m+\u001b[39m U \u001b[38;5;241m*\u001b[39m (X[s] \u001b[38;5;241m-\u001b[39m X[i])) \u001b[38;5;66;03m# MADE BOTH RESSART AND NORMAL USE THE CURRENT FLY RATHER THAN FORCING SELFLESS UPDATE\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m new_fitness \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflies_history\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_fitness \u001b[38;5;241m<\u001b[39m old_fitness:\n\u001b[0;32m     50\u001b[0m     fitness[i] \u001b[38;5;241m=\u001b[39m new_fitness\n",
      "Cell \u001b[1;32mIn[22], line 38\u001b[0m, in \u001b[0;36mf\u001b[1;34m(fly, flies_history, model, env)\u001b[0m\n\u001b[0;32m     35\u001b[0m action_mask \u001b[38;5;241m=\u001b[39m get_mask(info, n_actions\u001b[38;5;241m=\u001b[39menv\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 38\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[43mcloned_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(q_values)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     41\u001b[0m next_state, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[3], line 44\u001b[0m, in \u001b[0;36mQNetwork.forward\u001b[1;34m(self, x, action_masks)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, action_masks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 44\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m action_masks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m         q_values \u001b[38;5;241m=\u001b[39m q_values \u001b[38;5;241m-\u001b[39m ((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m action_masks) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e10\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "newweihgts = DFO(flies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('realbest_fly_weights.npy', newweihgts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
