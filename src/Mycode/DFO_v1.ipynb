{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State dict keys: odict_keys(['network.0.weight', 'network.0.bias', 'network.2.weight', 'network.2.bias', 'network.4.weight', 'network.4.bias'])\n",
      "Successfully loaded weights!\n",
      "\n",
      "Model Architecture:\n",
      "QNetwork(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=716, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=25, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordan Lankford\\AppData\\Local\\Temp\\ipykernel_22692\\2027990685.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Add the root directory to Python path\n",
    "root_dir = \"C:\\\\Users\\\\Jordan Lankford\\\\Documents\\\\GitHub\\\\FineTune-DQN\"\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "\n",
    "# Now imports should work\n",
    "from src.utils.utils import set_seeds\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from src.utils.utils import set_seeds\n",
    "from torchsummary import summary\n",
    "\n",
    "def encode_state(obs, n_states):\n",
    "    obs = torch.Tensor(obs)\n",
    "    return nn.functional.one_hot(obs.long(), n_states).float()\n",
    "\n",
    "def get_mask(info, n_actions=25):\n",
    "    allowed_actions = info['admissible_actions']\n",
    "    mask = np.zeros(n_actions)\n",
    "    mask[allowed_actions] = 1\n",
    "    return torch.Tensor(mask).unsqueeze(0)\n",
    "\n",
    "# Modified QNetwork to match the deep DQN structure\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.n_states = env.observation_space.n\n",
    "        self.n_actions = env.action_space.n\n",
    "        \n",
    "        # Match the architecture of the deep DQN\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(self.n_states, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, self.n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, action_masks=None):\n",
    "        q_values = self.network(x)\n",
    "        if action_masks is not None:\n",
    "            q_values = q_values - ((1 - action_masks) * 1e10)\n",
    "        return q_values\n",
    "\n",
    "# Create environment and network\n",
    "env = gym.make('Sepsis/ICU-Sepsis-v2')\n",
    "q_network = QNetwork(env)\n",
    "\n",
    "# Load the trained deep DQN weights\n",
    "model_path = r\"C:\\Users\\Jordan Lankford\\Documents\\GitHub\\FineTune-DQN\\models\\dqn\\dqn_final_seed_0.pt\"\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# Print the keys in the state dict to verify structure\n",
    "print(\"State dict keys:\", state_dict.keys())\n",
    "\n",
    "# Load the weights\n",
    "try:\n",
    "    q_network.load_state_dict(state_dict)\n",
    "    print(\"Successfully loaded weights!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading weights: {e}\")\n",
    "    # Try loading with strict=False if there are issues\n",
    "    q_network.load_state_dict(state_dict, strict=False)\n",
    "    print(\"Loaded weights with strict=False\")\n",
    "\n",
    "# Print model structure\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(q_network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([128, 716]), torch.Size([128]), torch.Size([128, 128]), torch.Size([128]), torch.Size([25, 128]), torch.Size([25])]\n"
     ]
    }
   ],
   "source": [
    "weight_shapes = []\n",
    "for param in q_network.parameters():\n",
    "    weight_shapes.append(param.shape)\n",
    "print(weight_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(91648), np.int64(128), np.int64(16384), np.int64(128), np.int64(3200), np.int64(25)]\n"
     ]
    }
   ],
   "source": [
    "values_in_dimension=[]\n",
    "for shape in weight_shapes:\n",
    "    values_in_dimension.append(np.prod(shape))\n",
    "print(values_in_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [param.detach().numpy() for param in q_network.parameters()]  # Get all model weights as numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "\n",
    "def f(fly, flies_history = None, model=q_network,env=env):\n",
    "    \n",
    "    cloned_model = q_network\n",
    "    \n",
    "    # Reshape fly's weights to match the model's weight shape\n",
    "    reshaped_fly = reshape_to_model_weights(fly, model)\n",
    "    \n",
    "    # Load the reshaped weights into the cloned model\n",
    "    cloned_model.load_state_dict(dict(zip([name for name, _ in cloned_model.named_parameters()], reshaped_fly)))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    cloned_model.eval()\n",
    "\n",
    "    # Run the evaluation (similar to what is done in evaluate_network)\n",
    "    episode_rewards = []\n",
    "    episode_lengths = []\n",
    "    \n",
    "    num_episodes = 10000  # or any other number you'd like to test  USE 10000 FOR STABAL ISH\n",
    "    for episode in range(num_episodes):\n",
    "        state, info = env.reset()\n",
    "        episode_reward = 0\n",
    "        steps = 0\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            state_encoded = encode_state(np.array([state]), env.observation_space.n)\n",
    "            action_mask = get_mask(info, n_actions=env.action_space.n)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                q_values = cloned_model(state_encoded, action_mask)\n",
    "                action = torch.argmax(q_values).item()\n",
    "            \n",
    "            next_state, reward, terminated, truncated, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "            steps += 1\n",
    "            state = next_state\n",
    "            done = terminated or truncated\n",
    "\n",
    "        episode_rewards.append(episode_reward)\n",
    "        episode_lengths.append(steps)\n",
    "    \n",
    "\n",
    "    fitness = np.mean(episode_rewards)\n",
    "    # Return the average reward (or any other metric you want)\n",
    "    #return -f_avrg(fitness, flies_history)\n",
    "    return -fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sequential evaluation:\n",
      "Sequential result: -0.809\n",
      "Sequential time: 33.63s\n",
      "\n",
      "Testing parallel evaluation:\n",
      "Evaluated 10000 episodes in 50.38 seconds\n",
      "Parallel result: -0.8062\n",
      "Parallel time: 50.39s\n",
      "\n",
      "Speedup: 0.67x\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from parallel_fitness import parallel_fitness, QNetwork\n",
    "import time \n",
    "\n",
    "def f_parallel(fly, model=q_network, num_processes=4):\n",
    "    \"\"\"\n",
    "    Wrapper for parallel fitness evaluation\n",
    "    \"\"\"\n",
    "    reshaped_fly = reshape_to_model_weights(fly, model)\n",
    "    state_dict = dict(zip([name for name, _ in model.named_parameters()], reshaped_fly))\n",
    "    return parallel_fitness(state_dict, num_processes=num_processes)\n",
    "\n",
    "\n",
    "# Compare performance\n",
    "print(\"Testing sequential evaluation:\")\n",
    "start = time.perf_counter()\n",
    "result_seq = f(flies[0])\n",
    "time_seq = time.perf_counter() - start\n",
    "print(f\"Sequential result: {result_seq}\")\n",
    "print(f\"Sequential time: {time_seq:.2f}s\")\n",
    "\n",
    "print(\"\\nTesting parallel evaluation:\")\n",
    "start = time.perf_counter()\n",
    "result_par = f_parallel(flies[0], num_processes=4)\n",
    "time_par = time.perf_counter() - start\n",
    "print(f\"Parallel result: {result_par}\")\n",
    "print(f\"Parallel time: {time_par:.2f}s\")\n",
    "\n",
    "print(f\"\\nSpeedup: {time_seq/time_par:.2f}x\")'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing vectorized evaluation:\n",
      "Evaluated 1068 episodes in 2.43 seconds\n",
      "Vectorized result: -0.0\n",
      "Vectorized time: 3.88s\n",
      "Testing sequential evaluation:\n",
      "Sequential result: -0.8124\n",
      "Sequential time: 37.90s\n",
      "\n",
      "Speedup: 9.77x\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "from vectorized_fitness import vectorized_fitness, QNetwork\n",
    "import time\n",
    "\n",
    "def f_vectorized(fly, model=q_network, num_envs=4):\n",
    "    \"\"\"\n",
    "    Wrapper for vectorized fitness evaluation\n",
    "    \"\"\"\n",
    "    reshaped_fly = reshape_to_model_weights(fly, model)\n",
    "    state_dict = dict(zip([name for name, _ in model.named_parameters()], reshaped_fly))\n",
    "    return vectorized_fitness(state_dict, num_envs=num_envs)\n",
    "\n",
    "# Test code\n",
    "\n",
    "\n",
    "print(\"\\nTesting vectorized evaluation:\")\n",
    "start = time.perf_counter()\n",
    "result_vec = f_vectorized(flies[0], num_envs=4)\n",
    "time_vec = time.perf_counter() - start\n",
    "print(f\"Vectorized result: {result_vec}\")\n",
    "print(f\"Vectorized time: {time_vec:.2f}s\")\n",
    "\n",
    "\n",
    "print(\"Testing sequential evaluation:\")\n",
    "start = time.perf_counter()\n",
    "result_seq = f(flies[0])\n",
    "time_seq = time.perf_counter() - start\n",
    "print(f\"Sequential result: {result_seq}\")\n",
    "print(f\"Sequential time: {time_seq:.2f}s\")\n",
    "\n",
    "print(f\"\\nSpeedup: {time_seq/time_vec:.2f}x\")'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_model_weights(flattened_fly, model=q_network):\n",
    "    # List to store reshaped weights\n",
    "    reshaped_weights = []\n",
    "    counter = 0  # Counter for elements in fly\n",
    "    \n",
    "    # Get the shapes of the model's parameters\n",
    "    values_in_dimension = [param.numel() for param in model.parameters()]\n",
    "    weight_shapes = [param.shape for param in model.parameters()]\n",
    "    \n",
    "    for i in range(len(values_in_dimension)):\n",
    "        # Get the flattened weights for this layer\n",
    "        weight_flat = flattened_fly[counter: counter + values_in_dimension[i]]\n",
    "        \n",
    "        # Reshape and convert to torch.Tensor\n",
    "        reshaped_layer_weights = torch.tensor(weight_flat, dtype=torch.float32).reshape(weight_shapes[i])\n",
    "        \n",
    "        # Append the reshaped weight to the list\n",
    "        reshaped_weights.append(reshaped_layer_weights)\n",
    "        \n",
    "        # Move the counter to the next parameter block\n",
    "        counter += values_in_dimension[i]\n",
    "    \n",
    "    return reshaped_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_flies_from_model(number_of_flies, weights, model, inclusive):\n",
    "    population = []\n",
    "\n",
    "    if inclusive == False:\n",
    "        for i in range(number_of_flies):\n",
    "            fly = []  # This will hold the flattened weights for a single fly\n",
    "            \n",
    "            for param in model.parameters():  # Iterate through model parameters (weights and biases)\n",
    "                # Generate random weights with the same shape as the model's weight matrix\n",
    "                scalers = np.random.uniform(0.9, 1.1, size=param.shape)\n",
    "                print(param.shape)  # Print the shape to see what the weights look like\n",
    "                scaledweights = param.detach().numpy() * scalers  # Multiply the weight values by the scalers\n",
    "                \n",
    "                # Flatten the random weights and add them to the fly\n",
    "                flattened_weights = scaledweights.flatten()\n",
    "                fly.append(flattened_weights)\n",
    "            \n",
    "            # After flattening each layer's weights, flatten the entire fly and add to population\n",
    "            population.append(np.concatenate(fly))  # Concatenate the list of flattened weight arrays\n",
    "            \n",
    "    if inclusive == True:\n",
    "        for i in range(number_of_flies):\n",
    "            fly = []  # This will hold the flattened weights for a single fly\n",
    "            \n",
    "            for param in model.parameters():  # Iterate through model parameters (weights and biases)\n",
    "                if i == 0:\n",
    "                    flattened_weights = param.detach().numpy().flatten()  # Get the flattened weights for the first fly\n",
    "                    fly.append(flattened_weights)\n",
    "                else:\n",
    "                    scalers = np.random.uniform(0.9, 1.1, size=param.shape)\n",
    "                    print(param.shape)  # Print the shape to see what the weights look like\n",
    "                    scaledweights = param.detach().numpy() * scalers  # Multiply the weight values by the scalers\n",
    "                    \n",
    "                    # Flatten the random weights and add them to the fly\n",
    "                    flattened_weights = scaledweights.flatten()\n",
    "                    fly.append(flattened_weights)\n",
    "                \n",
    "            # After flattening each layer's weights, flatten the entire fly and add to population\n",
    "            population.append(np.concatenate(fly))  # Concatenate the list of flattened weight arrays\n",
    "        \n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n",
      "torch.Size([128, 716])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([25, 128])\n",
      "torch.Size([25])\n"
     ]
    }
   ],
   "source": [
    "num_of_flies = 10\n",
    "\n",
    "flies = initialize_flies_from_model(num_of_flies,weights,q_network,True)\n",
    "\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "max_history = 5\n",
    "flies_history = [deque(maxlen=max_history) for _ in range(num_of_flies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([], maxlen=5)\n"
     ]
    }
   ],
   "source": [
    "print(flies_history[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_avrg(fitness, flies_history):\n",
    "\n",
    "    flies_history.append(fitness)\n",
    "\n",
    "    print(flies_history)\n",
    "\n",
    "    return sum(flies_history) / len(flies_history) # mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(flies[0],flies_history[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(flies)\t\t\t# POPULATION SIZE\n",
    "D = len(flies[0])\t\t\t\t\t# DIMENSIONALITY \n",
    "delta = 0.005\t\t\t# DISTURBANCE THRESHOLD \n",
    "maxIterations = 200\t# ITERATIONS ALLOWED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFO(start_flies):\n",
    "    \"\"\"\n",
    "    DFO with initial history population phase\n",
    "    \"\"\"\n",
    "    X = np.array(start_flies)     \n",
    "    fitness = np.zeros(N)         \n",
    "    flies_history = [deque(maxlen=5) for _ in range(N)]\n",
    "\n",
    "    # First phase: Populate histories for all flies\n",
    "    print(\"Populating initial histories...\")\n",
    "    for _ in range(max_history):  # Run evaluations to fill histories\n",
    "        for i in range(N):\n",
    "            fitness[i] = f(X[i], flies_history[i])\n",
    "            print(f\"Fly {i} history: {list(flies_history[i])}\")\n",
    "    \n",
    "    # Now all flies have full histories, start optimization\n",
    "    s = np.argmin(fitness)\n",
    "    print(f\"\\nStarting optimization with best fly: {s}, fitness: {fitness[s]:.3f}\")\n",
    "    \n",
    "    # Main DFO loop\n",
    "    for itr in range(maxIterations):\n",
    "        # Recalculate best fly's fitness\n",
    "        best_fly_fitness = f(X[s], flies_history[s])\n",
    "        fitness[s] = best_fly_fitness\n",
    "        \n",
    "        print(f\"\\nIteration: {itr}\")\n",
    "        print(f\"Best fly {s} recalculated fitness: {fitness[s]:.3f}\")\n",
    "        print(f\"Best fly history: {list(flies_history[s])}\")\n",
    "\n",
    "        for i in range(N):\n",
    "            if i == s:\n",
    "                continue\n",
    "\n",
    "            left = (i-1) % N\n",
    "            right = (i+1) % N\n",
    "            bNeighbour = right if fitness[right] < fitness[left] else left\n",
    "\n",
    "            old_position = X[i].copy()\n",
    "            old_fitness = fitness[i]\n",
    "\n",
    "            U = np.random.uniform(0, 1, D)\n",
    "            R = np.random.uniform(0, 1, D)\n",
    "            X[i] = np.where(R < delta,\n",
    "                           np.random.normal(loc=X[bNeighbour], scale=delta),\n",
    "                           X[bNeighbour] + U * (X[s] - X[bNeighbour]))\n",
    "\n",
    "            new_fitness = f(X[i], flies_history[i])\n",
    "            \n",
    "            if new_fitness < old_fitness:\n",
    "                fitness[i] = new_fitness\n",
    "                if new_fitness < fitness[s]:\n",
    "                    s = i\n",
    "                    print(f\"New best found! Fly {i}: {new_fitness:.3f}\")\n",
    "                    print(f\"New best history: {list(flies_history[i])}\")\n",
    "            else:\n",
    "                X[i] = old_position\n",
    "                fitness[i] = old_fitness\n",
    "\n",
    "        # After all flies updated, recheck who is best\n",
    "        s = np.argmin(fitness)\n",
    "        print(f\"End of iteration best fly: {s} with fitness: {fitness[s]:.3f}\")\n",
    "        print(f\"Best fly history: {list(flies_history[s])}\")\n",
    "\n",
    "    return X[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newweihgts = DFO(flies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('realbest_fly_weights.npy', newweihgts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
